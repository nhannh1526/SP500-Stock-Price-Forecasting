{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIc-3-cxvsbQ",
        "outputId": "ec26aaba-409b-48d2-cb5c-a859fcc2d911"
      },
      "outputs": [],
      "source": [
        "from utilities import *\n",
        "from statsmodels.tsa.arima.model import ARIMA, ARIMAResults\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from rnn import RNNModel\n",
        "from lstm import LSTMModel\n",
        "from gru import GRUModel\n",
        "from optimization import Optimization\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNYK6JrxwBMB"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "SUBDATASET_PATH = \"data/subdataset/\"\n",
        "MODELS_PATH = \"models\"\n",
        "\n",
        "HIDDEN_DIM = 64\n",
        "LAYER_DIM = 3\n",
        "BATCH_SIZE = 32\n",
        "DROPOUT = 0.3\n",
        "N_EPOCHS = 100\n",
        "LEARNING_RATE = 1e-03\n",
        "WEIGHT_RATE = 1e-05\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c7RfPfpwDVY"
      },
      "outputs": [],
      "source": [
        "result_dict = {}\n",
        "\n",
        "for ticker in tqdm_notebook(os.listdir(SUBDATASET_PATH), desc=\"\"):\n",
        "\n",
        "    df = pd.read_csv(SUBDATASET_PATH+ticker, index_col=\"Date\")\n",
        "    df[\"Next 5 Days Close\"] = df[\"Close\"].shift(-5)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "        df, \"Next 5 Days Close\", 0.1)\n",
        "    X_train_arr, X_val_arr, X_test_arr, y_train_arr, y_val_arr, y_test_arr, scaler = transform_data(\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test, scaling=\"minmax\")\n",
        "    train_loader, val_loader, test_loader = load_data_into_dataloader(\n",
        "        X_train_arr, X_val_arr, X_test_arr, y_train_arr, y_val_arr, y_test_arr, batch_size=BATCH_SIZE)\n",
        "\n",
        "    input_dim = len(X_train.columns)\n",
        "    output_dim = len(y_train.columns)\n",
        "\n",
        "    model_params = {\n",
        "        \"input_dim\": input_dim,\n",
        "        \"hidden_dim\": HIDDEN_DIM,\n",
        "        \"layer_dim\": LAYER_DIM,\n",
        "        \"output_dim\": output_dim,\n",
        "        \"dropout_prob\": DROPOUT\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for model_name in [\"RNN\", \"LSTM\", \"GRU\"]:\n",
        "\n",
        "        if model_name == \"RNN\":\n",
        "            model = RNNModel(**model_params)\n",
        "        elif model_name == \"LSTM\":\n",
        "            model = LSTMModel(**model_params)\n",
        "        else:\n",
        "            model = GRUModel(**model_params)\n",
        "\n",
        "        model_path = glob.glob(os.path.join(\n",
        "            MODELS_PATH, model_name, f\"{ticker.split('.')[0]}_*.pth\"), recursive=True)[0]\n",
        "        model = model.to(device)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "\n",
        "        loss_fn = nn.MSELoss(reduction=\"mean\")\n",
        "        optimizer = optim.Adam(\n",
        "            model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_RATE)\n",
        "        opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
        "\n",
        "        predictions, values = opt.evaluate(\n",
        "            test_loader,\n",
        "            batch_size=1,\n",
        "            n_features=input_dim\n",
        "        )\n",
        "        result = format_predictions(predictions, values, X_test, scaler)\n",
        "        RMSE, MAE, MAPE = get_evaluation_metrics(\n",
        "            result[\"true\"], result[\"pred\"])\n",
        "        results[model_name] = {\"RMSE\": RMSE, \"MAE\": MAE, \"MAPE\": MAPE}\n",
        "\n",
        "    ##########################################################\n",
        "    df = pd.read_csv(SUBDATASET_PATH+ticker, index_col=\"Date\")\n",
        "    df[\"Next 5 Days Close\"] = df[\"Close\"].shift(-5)\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    X = df.drop(\"Next 5 Days Close\", axis=1)\n",
        "    y = df[\"Next 5 Days Close\"]\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=.1, shuffle=False)\n",
        "\n",
        "    results_2 = {}\n",
        "    for model_name in list(set(os.listdir(MODELS_PATH)) - set([\"ARIMA\", \"RNN\", \"LSTM\", \"GRU\"])):\n",
        "        model_path = os.path.join(\n",
        "            MODELS_PATH, model_name, f\"{ticker.split('.')[0]}.joblib\")\n",
        "        model = joblib.load(model_path)\n",
        "        y_pred = model.predict(X_test)\n",
        "        RMSE, MAE, MAPE = get_evaluation_metrics(y_test, y_pred)\n",
        "        results_2[model_name] = {\"RMSE\": RMSE, \"MAE\": MAE, \"MAPE\": MAPE}\n",
        "\n",
        "    ###################################################################\n",
        "    y_train.reset_index(drop=True, inplace=True)\n",
        "    y_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    model_path = os.path.join(MODELS_PATH, \"ARIMA\",\n",
        "                              f\"{ticker.split('.')[0]}.pkl\")\n",
        "    model = ARIMAResults.load(model_path)\n",
        "    y_pred = model.forecast(len(y_test))\n",
        "    RMSE, MAE, MAPE = get_evaluation_metrics(y_test, y_pred)\n",
        "    results_2[\"ARIMA\"] = {\"RMSE\": RMSE, \"MAE\": MAE, \"MAPE\": MAPE}\n",
        "    result_dict[f\"{ticker.split('.')[0]}\"] = {**results_2, **results}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RbYGHu_A3eY"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"results.pickle\", \"wb\") as file:\n",
        "    pickle.dump(result_dict, file, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Evaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
